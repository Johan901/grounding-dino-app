# ğŸ¦• Grounding DINO App â€“ Sistema de LocalizaciÃ³n Visual Guiado por Texto

Esta es una aplicaciÃ³n web interactiva construida con **Python** y **Streamlit**, que permite a los usuarios realizar tareas de *Visual Grounding* mediante el modelo **Grounding DINO**. AdemÃ¡s, la aplicaciÃ³n es completamente portable gracias a su contenedor Docker. Con esta app, cualquier persona puede subir una imagen, escribir una descripciÃ³n en lenguaje natural (por ejemplo, "a red car"), y obtener la predicciÃ³n visual del objeto indicado, destacado con cajas delimitadoras (bounding boxes).

---

## âœ’ï¸ Autores del Proyecto

- **Johan Hurtado**
- **AndrÃ©s EnrÃ­quez**

Este proyecto fue desarrollado como una iniciativa para explorar la integraciÃ³n de modelos de lenguaje y visiÃ³n computacional en aplicaciones accesibles para el usuario final.

---

## ğŸ¯ Objetivo del Proyecto

El objetivo de esta aplicaciÃ³n es democratizar el acceso a modelos de detecciÃ³n basados en texto, permitiendo a cualquier persona interactuar con imÃ¡genes sin necesidad de conocer clases predefinidas. Basta con describir lo que desea localizar en la imagen, y el sistema se encargarÃ¡ del resto.

---

## â“ Â¿QuÃ© es Visual Grounding y por quÃ© es importante?

**Visual Grounding** es la tarea de localizar objetos en imÃ¡genes a partir de descripciones textuales. Es una tecnologÃ­a fundamental en aplicaciones como:
- Interfaces multimodales (ej. asistentes virtuales)
- EdiciÃ³n automÃ¡tica de imÃ¡genes
- NavegaciÃ³n autÃ³noma con lenguaje natural
- AnÃ¡lisis de imÃ¡genes mÃ©dicas guiado por texto

---

## ğŸ” Â¿QuÃ© es Grounding DINO?

**Grounding DINO** es un modelo de cÃ³digo abierto que combina:
- **DINO** (DETR con mejor entrenamiento) para detecciÃ³n de objetos
- **Modelos de lenguaje como BERT** para procesar descripciones en texto

Este modelo permite identificar objetos en una imagen a partir de **descripciones naturales**, sin estar limitado a un conjunto de clases fijas. EstÃ¡ entrenado con millones de pares texto-imagen y logra detecciÃ³n en entornos abiertos (*open-set detection*).

---

## ğŸ§  Arquitectura del Sistema

```text
Usuario (imagen + descripciÃ³n en texto)
        â†“
Interfaz Web en Streamlit
        â†“
Grounding DINO (Transformers en CPU)
        â†“
Procesamiento y visualizaciÃ³n con OpenCV
        â†“
Resultado: imagen anotada con bounding boxes
```

### Componentes:

- **Backbone Visual**: Swin Transformer
- **Text Encoder**: BERT base uncased
- **Cross-Modal Attention**: alinea texto e imagen
- **Decoder tipo DETR**: predice cajas de objetos relevantes al texto

---


## :sauropod: Modelo: Grounding DINO

Incluye: una estructura de texto, una estructura de imÃ¡genes, un potenciador de funciones, una selecciÃ³n de consultas guiada por idioma y un decodificador de modalidades cruzadas.
![arch](.asset/arch.png)

---

## ğŸš€ CÃ³mo Ejecutar la AplicaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/Johan901/grounding-dino-app.git
cd grounding-dino-app
```

### 2. Crear entorno virtual e instalar dependencias

```bash
python -m venv venv
venv\Scripts\activate     # En Windows
pip install -r requirements.txt
```

### 3. Descargar los pesos del modelo

Debes colocar el siguiente archivo en una carpeta `weights/`:

ğŸ“¥ [`groundingdino_swint_ogc.pth`](https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth)

### 4. Ejecutar la aplicaciÃ³n localmente

```bash
streamlit run app.py
```

---


---

## ğŸ³ Ejecutar con Docker

TambiÃ©n puedes correr la aplicaciÃ³n en un contenedor Docker sin necesidad de instalar dependencias localmente.

### 1. Clonar el repositorio

```bash
git clone https://github.com/Johan901/grounding-dino-app.git
cd grounding-dino-app
```

### 2. Construir la imagen Docker

```bash
docker build -t grounding-dino-app .
```

### 3. Ejecutar el contenedor

```bash
docker run -p 8501:8501 grounding-dino-app
```

### 4. Acceder desde el navegador

```
http://localhost:8501
```

> AsegÃºrate de tener el archivo `groundingdino_swint_ogc.pth` dentro de la carpeta `weights/` antes de construir la imagen.


## ğŸ§© Estructura del Proyecto

```text
GroundingDINO/
â”œâ”€â”€ app.py                    â† punto de entrada principal
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ Home.py               â† pÃ¡gina de bienvenida
â”‚   â”œâ”€â”€ Introduccion.py       â† explica visual grounding
â”‚   â”œâ”€â”€ Arquitectura.py       â† arquitectura explicada + grÃ¡fico
â”‚   â””â”€â”€ Inferencia.py         â† permite subir imagen y hacer predicciÃ³n
â”œâ”€â”€ groundingdino/            â† implementaciÃ³n del modelo original
â”œâ”€â”€ weights/                  â† pesos descargados del modelo
â”œâ”€â”€ examples/                 â† imÃ¡genes subidas por el usuario
â”œâ”€â”€ outputs/                  â† imÃ¡genes procesadas
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ TecnologÃ­as y LibrerÃ­as Utilizadas

- **Python 3.8**
- **Streamlit** (interfaz web)
- **PyTorch** (inferencia del modelo)
- **Transformers - Hugging Face**
- **OpenCV** (anotaciÃ³n de imÃ¡genes)
- **Plotly** (visualizaciones)
- **Lottie** (animaciones visuales)
- **PIL, NumPy, Matplotlib**

---

## ğŸ“ Aplicaciones PrÃ¡cticas

Este sistema puede adaptarse a:
- Interfaces con IA multimodal
- Plataformas de accesibilidad visual
- EducaciÃ³n en visiÃ³n computacional
- Herramientas de etiquetado automÃ¡tico de datasets
- EdiciÃ³n de imÃ¡genes orientada por lenguaje

---

## ğŸ“œ Licencia

Este proyecto ha sido creado con fines acadÃ©micos y de investigaciÃ³n. Su uso estÃ¡ permitido para propÃ³sitos educativos, experimentales y no comerciales.

---

## ğŸ“¬ Contacto

Para consultas, propuestas o colaboraciones:

ğŸ“§ johanhurtaalt@gmail.com  
ğŸ“§ enrriquezandres7@gmail.com

---

Â¡Gracias por utilizar nuestra aplicaciÃ³n de Grounding DINO! Esperamos que este proyecto te sea Ãºtil para aprender, explorar y construir nuevas ideas con visiÃ³n y lenguaje.